{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Response A       0.83      0.45      0.59        11\n",
      "  Response B       0.74      0.94      0.83        18\n",
      "\n",
      "    accuracy                           0.76        29\n",
      "   macro avg       0.79      0.70      0.71        29\n",
      "weighted avg       0.77      0.76      0.74        29\n",
      "\n",
      "Predicted Label: Response B\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the CSV data\n",
    "file_path = 'pastoral.csv'  \n",
    "pastoral_data = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = pastoral_data['job description']\n",
    "y = pastoral_data['label']\n",
    "\n",
    "# Vectorize the job descriptions using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Output the classification report to evaluate performance\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Function to predict the label for a given job description\n",
    "def predict_label(job_description):\n",
    "    # Vectorize the input job description\n",
    "    job_description_tfidf = vectorizer.transform([job_description])\n",
    "    \n",
    "    # Predict the label using the trained model\n",
    "    predicted_label = model.predict(job_description_tfidf)[0]\n",
    "    \n",
    "    return predicted_label\n",
    "\n",
    "# Example usage\n",
    "example_job_description = \"Manage and maintain sports fields to appropriate standards\"\n",
    "predicted_label = predict_label(example_job_description)\n",
    "\n",
    "print(f\"Predicted Label: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Response A       0.83      0.45      0.59        11\n",
      "  Response B       0.74      0.94      0.83        18\n",
      "\n",
      "    accuracy                           0.76        29\n",
      "   macro avg       0.79      0.70      0.71        29\n",
      "weighted avg       0.77      0.76      0.74        29\n",
      "\n",
      "Example Job Description: \"Manage and maintain sports fields to appropriate standards\"\n",
      "Original Label: Response B\n",
      "Predicted Label: Response B\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the CSV data\n",
    "file_path = 'pastoral.csv' \n",
    "pastoral_data = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = pastoral_data['job description']\n",
    "y = pastoral_data['label']\n",
    "\n",
    "# Vectorize the job descriptions using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train a Random Forest Classifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Output the classification report to evaluate performance\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Function to predict the label for a given job description and display original and predicted labels\n",
    "def predict_label(job_description, original_label):\n",
    "    # Vectorize the input job description\n",
    "    job_description_tfidf = vectorizer.transform([job_description])\n",
    "    \n",
    "    # Predict the label using the trained model\n",
    "    predicted_label = model.predict(job_description_tfidf)[0]\n",
    "    \n",
    "    # Output the formatted result\n",
    "    print(f\"Example Job Description: \\\"{job_description}\\\"\")\n",
    "    print(f\"Original Label: {original_label}\")\n",
    "    print(f\"Predicted Label: {predicted_label}\")\n",
    "\n",
    "# Example usage with an example job description\n",
    "example_job_description = \"Manage and maintain sports fields to appropriate standards\"\n",
    "original_label = \"Response B\"  # Replace this with the actual original label if available\n",
    "\n",
    "predict_label(example_job_description, original_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
      "Best Parameters: {'max_depth': None, 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Cross-validation mean score: 0.6869565217391305\n",
      "Classification Report for Best Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Response A       0.67      0.18      0.29        11\n",
      "  Response B       0.65      0.94      0.77        18\n",
      "\n",
      "    accuracy                           0.66        29\n",
      "   macro avg       0.66      0.56      0.53        29\n",
      "weighted avg       0.66      0.66      0.59        29\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the CSV data\n",
    "file_path = 'pastoral.csv'  # Replace with the correct path\n",
    "pastoral_data = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = pastoral_data['job description']\n",
    "y = pastoral_data['label']\n",
    "\n",
    "# Vectorize the job descriptions using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Set up the hyperparameter grid for Random Forest\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],  # Number of trees in the forest\n",
    "    'max_depth': [None, 10, 20],     # Maximum depth of the trees\n",
    "    'min_samples_split': [2, 5, 10], # Minimum number of samples required to split a node\n",
    "    'min_samples_leaf': [1, 2, 4],   # Minimum number of samples required at a leaf node\n",
    "}\n",
    "\n",
    "# Initialize a GridSearchCV object with cross-validation\n",
    "grid_search = GridSearchCV(estimator=RandomForestClassifier(random_state=42),\n",
    "                           param_grid=param_grid,\n",
    "                           cv=5,        # 5-fold cross-validation\n",
    "                           n_jobs=-1,   # Use all available cores\n",
    "                           verbose=1)\n",
    "\n",
    "# Fit the model to the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best hyperparameters found by GridSearchCV\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best Parameters: {best_params}\")\n",
    "\n",
    "# Train the RandomForestClassifier with the best hyperparameters\n",
    "best_model = RandomForestClassifier(**best_params, random_state=42)\n",
    "best_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model using cross-validation to get a more reliable score\n",
    "cv_scores = cross_val_score(best_model, X_train, y_train, cv=5)\n",
    "print(f\"Cross-validation mean score: {cv_scores.mean()}\")\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred_best = best_model.predict(X_test)\n",
    "\n",
    "# Output the classification report\n",
    "print(\"Classification Report for Best Model:\")\n",
    "print(classification_report(y_test, y_pred_best))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.1-py3-none-macosx_12_0_arm64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from xgboost) (1.26.2)\n",
      "Requirement already satisfied: scipy in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from xgboost) (1.11.4)\n",
      "Downloading xgboost-2.1.1-py3-none-macosx_12_0_arm64.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: xgboost\n",
      "Successfully installed xgboost-2.1.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (2.1.3)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.5.0-py3-none-macosx_12_0_arm64.whl.metadata (17 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from lightgbm) (1.26.2)\n",
      "Requirement already satisfied: scipy in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from lightgbm) (1.11.4)\n",
      "Downloading lightgbm-4.5.0-py3-none-macosx_12_0_arm64.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lightgbm\n",
      "Successfully installed lightgbm-4.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from scikit-learn) (1.26.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from scikit-learn) (3.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Job Description: \"Supervise and ensure proper use of all sports facilities\"\n",
      "Predicted Label: Response A\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Sample job descriptions (use your real dataset here)\n",
    "job_descriptions = [\"Manage and maintain sports fields to appropriate standards\",\n",
    "                    \"Provide support and advice on student well-being\",\n",
    "                    \"Handle the welfare of patients in a medical setting\"]\n",
    "\n",
    "# Sample corresponding labels for training (use actual labels from your dataset)\n",
    "labels = [\"Response A\", \"Response B\", \"Response A\"]\n",
    "\n",
    "# Convert categorical labels to numeric using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(labels)\n",
    "\n",
    "# Vectorize the job descriptions using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(job_descriptions)\n",
    "\n",
    "# Train a simple XGBoost classifier (assuming a small demo)\n",
    "model = XGBClassifier(random_state=42)\n",
    "model.fit(X_tfidf, y_encoded)\n",
    "\n",
    "# New job description to predict\n",
    "new_job_description = [\"Supervise and ensure proper use of all sports facilities\"]\n",
    "\n",
    "# Vectorize the new job description\n",
    "new_job_tfidf = vectorizer.transform(new_job_description)\n",
    "\n",
    "# Predict the label\n",
    "predicted_label_numeric = model.predict(new_job_tfidf)\n",
    "\n",
    "# Convert numeric prediction back to original label\n",
    "predicted_label = label_encoder.inverse_transform(predicted_label_numeric)\n",
    "\n",
    "# Display the result\n",
    "print(f\"Example Job Description: \\\"{new_job_description[0]}\\\"\")\n",
    "print(f\"Predicted Label: {predicted_label[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example Job Description: \"Providing support, advice, and information to graduates, including workshops and one-on-one sessions\"\n",
      "Original Label: Response B\n",
      "Predicted Label: Response B\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Load the CSV data\n",
    "file_path = 'pastoral.csv' \n",
    "pastoral_data = pd.read_csv(file_path, encoding='ISO-8859-1')\n",
    "\n",
    "# Split the data into features (X) and target (y)\n",
    "X = pastoral_data['job description']\n",
    "y = pastoral_data['label']\n",
    "\n",
    "# Convert categorical labels to numeric using LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Vectorize the job descriptions using TF-IDF\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "# Train a simple XGBoost classifier (you may already have a trained model)\n",
    "model = XGBClassifier(random_state=42)\n",
    "model.fit(X_tfidf, y_encoded)\n",
    "\n",
    "# New job description input (from user)\n",
    "new_job_description = \"Providing support, advice, and information to graduates, including workshops and one-on-one sessions\"\n",
    "\n",
    "# Find the original label from the dataset (if exists)\n",
    "original_label = pastoral_data[pastoral_data['job description'] == new_job_description]['label'].values\n",
    "if len(original_label) > 0:\n",
    "    original_label = original_label[0]\n",
    "else:\n",
    "    original_label = \"(Original label not found in dataset)\"\n",
    "\n",
    "# Vectorize the new job description\n",
    "new_job_tfidf = vectorizer.transform([new_job_description])\n",
    "\n",
    "# Predict the label\n",
    "predicted_label_numeric = model.predict(new_job_tfidf)\n",
    "\n",
    "# Convert numeric prediction back to original label\n",
    "predicted_label = label_encoder.inverse_transform(predicted_label_numeric)\n",
    "\n",
    "# Display the result in the desired format\n",
    "print(f\"Example Job Description: \\\"{new_job_description}\\\"\")\n",
    "print(f\"Original Label: {original_label}\")\n",
    "print(f\"Predicted Label: {predicted_label[0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“virtual”env”",
   "language": "python",
   "name": "myvirtualenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
