# Install necessary libraries
!pip install nltk pandas scikit-learn

import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, accuracy_score
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
import nltk

# Download necessary NLTK datasets
nltk.download('punkt')
nltk.download('stopwords')
nltk.download('wordnet')

# Load the dataset
data = pd.read_csv('labeled_job_descriptions.csv')

# Preprocessing function
def preprocess_text(text):
    lemmatizer = WordNetLemmatizer()
    tokens = word_tokenize(text.lower())
    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalpha() and token not in stopwords.words('english')]
    return ' '.join(tokens)

data['description'] = data['Job description'].apply(preprocess_text)

# Print unique labels to check for discrepancies
print("Unique labels in the dataset before mapping:", data['Label'].unique())

# Update the label mapping to match your dataset
label_mapping = {
    'Response A': 0,
    'Response B': 1,
    'Response C': 2,
    'Response D': 3,
    'Response E': 4,  # If 'Response E' exists
    'Response F': 5   # If 'Response F' exists
}

# Map the labels
data['Label'] = data['Label'].map(label_mapping)

# Check for any missing values in the Label column after mapping
if data['Label'].isnull().any():
    print("There are missing values in the Label column. Please check the data.")
    # Print rows with missing Labels
    print(data[data['Label'].isnull()])
else:
    # Splitting the data
    X_train, X_test, y_train, y_test = train_test_split(data['description'], data['Label'], test_size=0.2, random_state=42)

    # Building pipelines for different classifiers
    pipelines = {
        'Logistic Regression': Pipeline([
            ('tfidf', TfidfVectorizer()),
            ('clf', LogisticRegression(class_weight='balanced'))
        ]),
        'SVM': Pipeline([
            ('tfidf', TfidfVectorizer()),
            ('clf', SVC(class_weight='balanced', probability=True))
        ]),
        'Random Forest': Pipeline([
            ('tfidf', TfidfVectorizer()),
            ('clf', RandomForestClassifier(class_weight='balanced'))
        ])
    }

    # Define parameter grids for each classifier
    param_grids = {
        'Logistic Regression': {
            'tfidf__max_df': [0.8, 0.9, 1.0],
            'tfidf__min_df': [1, 2, 3],
            'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)],
            'clf__C': [0.1, 1, 10],
            'clf__solver': ['liblinear', 'lbfgs']
        },
        'SVM': {
            'tfidf__max_df': [0.8, 0.9, 1.0],
            'tfidf__min_df': [1, 2, 3],
            'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)],
            'clf__C': [0.1, 1, 10],
            'clf__kernel': ['linear', 'rbf']
        },
        'Random Forest': {
            'tfidf__max_df': [0.8, 0.9, 1.0],
            'tfidf__min_df': [1, 2, 3],
            'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)],
            'clf__n_estimators': [50, 100, 200]
        }
    }

    best_models = {}
    best_accuracy = 0
    best_model_name = None
    best_model = None

    # Perform GridSearchCV for each model
    for model_name in pipelines:
        print(f"Training {model_name}...")
        grid_search = GridSearchCV(pipelines[model_name], param_grids[model_name], cv=5, scoring='accuracy', n_jobs=-1, verbose=2)
        grid_search.fit(X_train, y_train)
        best_models[model_name] = grid_search.best_estimator_
        accuracy = grid_search.best_score_
        print(f"{model_name} best params: {grid_search.best_params_}")
        print(f"{model_name} best accuracy: {accuracy}")

        # Evaluate each model on the test set
        y_pred = best_models[model_name].predict(X_test)
        print(f'\n{model_name} classification report on test set:')
        print(classification_report(y_test, y_pred))

        # Check if this model is the best so far
        if accuracy > best_accuracy:
            best_accuracy = accuracy
            best_model_name = model_name
            best_model = best_models[model_name]

    print(f"\nBest model is {best_model_name} with accuracy of {best_accuracy}")

    # Function to predict the response for a new job description using the best model
    def predict_response(job_description):
        processed_description = preprocess_text(job_description)
        prediction = best_model.predict([processed_description])[0]
        reverse_label_mapping = {v: k for k, v in label_mapping.items()}
        return reverse_label_mapping[prediction]

    # Example usage
    new_job_description = "Manage university financial reports and budget forecasting."
    predicted_response = predict_response(new_job_description)
    print(f'Predicted Response: {predicted_response}')

    new_job_description_other = "Assist in organizing office files and managing schedules."
    predicted_response_other = predict_response(new_job_description_other)
    print(f'Predicted Response: {predicted_response_other}')
