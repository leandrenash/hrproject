{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\nosao\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\nosao\\anaconda3\\lib\\site-packages (2.1.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nosao\\anaconda3\\lib\\site-packages (1.2.2)\n",
      "Requirement already satisfied: click in c:\\users\\nosao\\anaconda3\\lib\\site-packages (from nltk) (8.1.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\nosao\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\nosao\\anaconda3\\lib\\site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nosao\\anaconda3\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in c:\\users\\nosao\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nosao\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nosao\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\nosao\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\nosao\\anaconda3\\lib\\site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nosao\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nosao\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nosao\\anaconda3\\lib\\site-packages (from click->nltk) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nosao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nosao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nosao\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in the dataset before mapping: ['Response C' 'Response B' 'Response A' 'Response D']\n",
      "Training Logistic Regression...\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nosao\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression best params: {'clf__C': 10, 'clf__solver': 'lbfgs', 'tfidf__max_df': 0.8, 'tfidf__min_df': 3, 'tfidf__ngram_range': (1, 2)}\n",
      "Logistic Regression best accuracy: 0.9385507246376813\n",
      "Training SVM...\n",
      "Fitting 5 folds for each of 162 candidates, totalling 810 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nosao\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM best params: {'clf__C': 10, 'clf__kernel': 'linear', 'tfidf__max_df': 0.8, 'tfidf__min_df': 3, 'tfidf__ngram_range': (1, 1)}\n",
      "SVM best accuracy: 0.9211594202898551\n",
      "Training Random Forest...\n",
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nosao\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_split.py:700: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest best params: {'clf__n_estimators': 50, 'tfidf__max_df': 1.0, 'tfidf__min_df': 3, 'tfidf__ngram_range': (1, 1)}\n",
      "Random Forest best accuracy: 0.9206763285024154\n",
      "\n",
      "Best model is Logistic Regression with accuracy of 0.9385507246376813\n",
      "\n",
      "Logistic Regression classification report on test set:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.83      0.77        18\n",
      "           2       0.90      0.87      0.88        30\n",
      "           3       1.00      0.78      0.88         9\n",
      "\n",
      "    accuracy                           0.84        57\n",
      "   macro avg       0.87      0.83      0.84        57\n",
      "weighted avg       0.86      0.84      0.84        57\n",
      "\n",
      "Predicted Response: Response C\n",
      "Predicted Response: Response C\n"
     ]
    }
   ],
   "source": [
    "# Install necessary libraries\n",
    "!pip install nltk pandas scikit-learn\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "\n",
    "# Download necessary NLTK datasets\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('labeled_job_descriptions.csv')\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.isalpha() and token not in stopwords.words('english')]\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "data['description'] = data['Job description'].apply(preprocess_text)\n",
    "\n",
    "# Print unique labels to check for discrepancies\n",
    "print(\"Unique labels in the dataset before mapping:\", data['Label'].unique())\n",
    "\n",
    "# Update the label mapping to match your dataset\n",
    "label_mapping = {\n",
    "    'Response A': 0,\n",
    "    'Response B': 1,\n",
    "    'Response C': 2,\n",
    "    'Response D': 3,\n",
    "    'Response E': 4,  # If 'Response E' exists\n",
    "    'Response F': 5   # If 'Response F' exists\n",
    "}\n",
    "\n",
    "# Map the labels\n",
    "data['Label'] = data['Label'].map(label_mapping)\n",
    "\n",
    "# Check for any missing values in the Label column after mapping\n",
    "if data['Label'].isnull().any():\n",
    "    print(\"There are missing values in the Label column. Please check the data.\")\n",
    "    # Print rows with missing Labels\n",
    "    print(data[data['Label'].isnull()])\n",
    "else:\n",
    "    # Splitting the data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data['description'], data['Label'], test_size=0.2, random_state=42)\n",
    "\n",
    "    # Building pipelines for different classifiers\n",
    "    pipelines = {\n",
    "        'Logistic Regression': Pipeline([\n",
    "            ('tfidf', TfidfVectorizer()),\n",
    "            ('clf', LogisticRegression(class_weight='balanced'))\n",
    "        ]),\n",
    "        'SVM': Pipeline([\n",
    "            ('tfidf', TfidfVectorizer()),\n",
    "            ('clf', SVC(class_weight='balanced', probability=True))\n",
    "        ]),\n",
    "        'Random Forest': Pipeline([\n",
    "            ('tfidf', TfidfVectorizer()),\n",
    "            ('clf', RandomForestClassifier(class_weight='balanced'))\n",
    "        ])\n",
    "    }\n",
    "\n",
    "    # Define parameter grids for each classifier\n",
    "    param_grids = {\n",
    "        'Logistic Regression': {\n",
    "            'tfidf__max_df': [0.8, 0.9, 1.0],\n",
    "            'tfidf__min_df': [1, 2, 3],\n",
    "            'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "            'clf__C': [0.1, 1, 10],\n",
    "            'clf__solver': ['liblinear', 'lbfgs']\n",
    "        },\n",
    "        'SVM': {\n",
    "            'tfidf__max_df': [0.8, 0.9, 1.0],\n",
    "            'tfidf__min_df': [1, 2, 3],\n",
    "            'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "            'clf__C': [0.1, 1, 10],\n",
    "            'clf__kernel': ['linear', 'rbf']\n",
    "        },\n",
    "        'Random Forest': {\n",
    "            'tfidf__max_df': [0.8, 0.9, 1.0],\n",
    "            'tfidf__min_df': [1, 2, 3],\n",
    "            'tfidf__ngram_range': [(1, 1), (1, 2), (2, 2)],\n",
    "            'clf__n_estimators': [50, 100, 200]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    best_models = {}\n",
    "    best_accuracy = 0\n",
    "    best_model_name = None\n",
    "\n",
    "    # Perform GridSearchCV for each model\n",
    "    for model_name in pipelines:\n",
    "        print(f\"Training {model_name}...\")\n",
    "        grid_search = GridSearchCV(pipelines[model_name], param_grids[model_name], cv=5, scoring='accuracy', n_jobs=-1, verbose=2)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_models[model_name] = grid_search.best_estimator_\n",
    "        accuracy = grid_search.best_score_\n",
    "        print(f\"{model_name} best params: {grid_search.best_params_}\")\n",
    "        print(f\"{model_name} best accuracy: {accuracy}\")\n",
    "\n",
    "        # Check if this model is the best so far\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_model_name = model_name\n",
    "\n",
    "    print(f\"\\nBest model is {best_model_name} with accuracy of {best_accuracy}\")\n",
    "\n",
    "    # Evaluate the best model on the test set\n",
    "    best_model = best_models[best_model_name]\n",
    "    y_pred = best_model.predict(X_test)\n",
    "    print(f'\\n{best_model_name} classification report on test set:')\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    # Function to predict the response for a new job description using the best model\n",
    "    def predict_response(job_description):\n",
    "        processed_description = preprocess_text(job_description)\n",
    "        prediction = best_model.predict([processed_description])[0]\n",
    "        reverse_label_mapping = {v: k for k, v in label_mapping.items()}\n",
    "        return reverse_label_mapping[prediction]\n",
    "\n",
    "    # Example usage\n",
    "    new_job_description = \"Manage university financial reports and budget forecasting.\"\n",
    "    predicted_response = predict_response(new_job_description)\n",
    "    print(f'Predicted Response: {predicted_response}')\n",
    "\n",
    "    new_job_description_other = \"Assist in organizing office files and managing schedules.\"\n",
    "    predicted_response_other = predict_response(new_job_description_other)\n",
    "    print(f'Predicted Response: {predicted_response_other}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Response: Response A\n"
     ]
    }
   ],
   "source": [
    "new_job_description = \"The Director of PMO & Strategic Change will lead the delivery of the University’s strategic change portfolio and Programme Management Offices. The Director will work in partnership with senior leaders and key stakeholders across the institution to ensure the delivery of the strategic change programme that underpins delivery of the University’s strategic plan.\"\n",
    "predicted_response = predict_response(new_job_description)\n",
    "print(f'Predicted Response: {predicted_response}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
