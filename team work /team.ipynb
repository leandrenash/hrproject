{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (2.1.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from pandas) (1.26.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from scikit-learn) (1.11.4)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from scikit-learn) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/leandrenash/anaconda3/envs/myvirutalenv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pandas scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Response A       0.74      0.91      0.82        34\n",
      "  Response B       0.72      0.62      0.67        21\n",
      "  Response C       0.67      0.25      0.36         8\n",
      "\n",
      "    accuracy                           0.73        63\n",
      "   macro avg       0.71      0.59      0.62        63\n",
      "weighted avg       0.72      0.73      0.71        63\n",
      "\n",
      "Predicted label for the given job description: Response B\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('team.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Clean column names by stripping whitespaces\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Prepare the data\n",
    "X = data['Job Description']  # Features (Job Descriptions)\n",
    "y = data['label']  # Target (Labels)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Convert text data into numerical features using TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Function to predict the label for a new job description\n",
    "def predict_job_label(description):\n",
    "    description_tfidf = vectorizer.transform([description])  # Convert input text to TF-IDF features\n",
    "    prediction = model.predict(description_tfidf)  # Make prediction\n",
    "    return prediction[0]  # Return the predicted label\n",
    "\n",
    "# Example usage:\n",
    "new_description = input(\"Enter a job description: \")\n",
    "predicted_label = predict_job_label(new_description)\n",
    "print(f\"Predicted label for the given job description: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Response A       0.74      0.91      0.82        34\n",
      "  Response B       0.72      0.62      0.67        21\n",
      "  Response C       0.67      0.25      0.36         8\n",
      "\n",
      "    accuracy                           0.73        63\n",
      "   macro avg       0.71      0.59      0.62        63\n",
      "weighted avg       0.72      0.73      0.71        63\n",
      "\n",
      "\n",
      "Test Set Results:\n",
      "\n",
      "                                       Job Description Original Label  \\\n",
      "30     Develop interactive data reports and dashboards     Response B   \n",
      "172  Provide guidance on campaign strategies and co...     Response A   \n",
      "84     Manage contracts for campus facilities services     Response B   \n",
      "199  Occasionally assist with training staff on AV ...     Response C   \n",
      "60                Provide financial advice to students     Response B   \n",
      "..                                                 ...            ...   \n",
      "65      Ensure tools and materials are well maintained     Response B   \n",
      "5    Provide occasional training on communications ...     Response B   \n",
      "146    Lead meetings and ensure key objectives are met     Response A   \n",
      "56       Oversee troubleshooting and technical support     Response A   \n",
      "97   Train staff on maintenance protocols and safet...     Response A   \n",
      "\n",
      "    Predicted Label  \n",
      "30       Response B  \n",
      "172      Response A  \n",
      "84       Response B  \n",
      "199      Response C  \n",
      "60       Response B  \n",
      "..              ...  \n",
      "65       Response B  \n",
      "5        Response A  \n",
      "146      Response A  \n",
      "56       Response A  \n",
      "97       Response A  \n",
      "\n",
      "[63 rows x 3 columns]\n",
      "\n",
      "Predicted label for the given job description: Response B\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('team.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Clean column names by stripping whitespaces\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Prepare the data\n",
    "X = data['Job Description']  # Features (Job Descriptions)\n",
    "y = data['label']  # Target (Labels)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Convert text data into numerical features using TF-IDF Vectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the RandomForestClassifier\n",
    "model = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test_tfidf)\n",
    "\n",
    "# Display classification report\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Combine the test set results (Job Description, Original Label, and Predicted Label)\n",
    "results_df = pd.DataFrame({\n",
    "    'Job Description': X_test,\n",
    "    'Original Label': y_test,\n",
    "    'Predicted Label': y_pred\n",
    "})\n",
    "\n",
    "# Display the output (Job Description, Original Label, Predicted Label)\n",
    "print(\"\\nTest Set Results:\\n\")\n",
    "print(results_df)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv('test_set_predictions.csv', index=False)\n",
    "\n",
    "# Example usage to predict a label for a new job description:\n",
    "def predict_job_label(description):\n",
    "    description_tfidf = vectorizer.transform([description])  # Convert input text to TF-IDF features\n",
    "    prediction = model.predict(description_tfidf)  # Make prediction\n",
    "    return prediction[0]  # Return the predicted label\n",
    "\n",
    "# Predict a new job description (optional)\n",
    "new_description = input(\"\\nEnter a job description: \")\n",
    "predicted_label = predict_job_label(new_description)\n",
    "print(f\"\\nPredicted label for the given job description: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters Found:\n",
      " {'rf__n_estimators': 100, 'rf__min_samples_split': 2, 'rf__min_samples_leaf': 1, 'rf__max_depth': 30}\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Response A       0.88      0.85      0.87        34\n",
      "  Response B       0.65      0.81      0.72        21\n",
      "  Response C       0.75      0.38      0.50         8\n",
      "\n",
      "    accuracy                           0.78        63\n",
      "   macro avg       0.76      0.68      0.70        63\n",
      "weighted avg       0.79      0.78      0.77        63\n",
      "\n",
      "\n",
      "Test Set Results:\n",
      "\n",
      "                                       Job Description Original Label  \\\n",
      "30           develop interactive data report dashboard     Response B   \n",
      "172   provide guidance campaign strategy communication     Response A   \n",
      "84             manage contract campus facility service     Response B   \n",
      "199  occasionally assist training staff av equipmen...     Response C   \n",
      "60                    provide financial advice student     Response B   \n",
      "..                                                 ...            ...   \n",
      "65                ensure tool material well maintained     Response B   \n",
      "5    provide occasional training communication stra...     Response B   \n",
      "146              lead meeting ensure key objective met     Response A   \n",
      "56           oversee troubleshooting technical support     Response A   \n",
      "97     train staff maintenance protocol safety measure     Response A   \n",
      "\n",
      "    Predicted Label  \n",
      "30       Response B  \n",
      "172      Response B  \n",
      "84       Response B  \n",
      "199      Response C  \n",
      "60       Response B  \n",
      "..              ...  \n",
      "65       Response B  \n",
      "5        Response A  \n",
      "146      Response A  \n",
      "56       Response C  \n",
      "97       Response A  \n",
      "\n",
      "[63 rows x 3 columns]\n",
      "\n",
      "Predicted label for the given job description: Response B\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "# Uncomment these lines if you haven't downloaded NLTK resources yet\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('team.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Clean column names by stripping whitespaces\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Preprocessing function to clean and lemmatize text\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Lemmatize and remove stopwords\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Apply the preprocessing to job descriptions\n",
    "data['Job Description'] = data['Job Description'].apply(preprocess_text)\n",
    "\n",
    "# Prepare the data\n",
    "X = data['Job Description']  # Features (Job Descriptions)\n",
    "y = data['label']  # Target (Labels)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a pipeline that includes both TF-IDF Vectorizer and RandomForestClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('rf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Hyperparameter tuning using RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    'rf__n_estimators': [50, 100, 200, 300],\n",
    "    'rf__max_depth': [10, 20, 30, None],\n",
    "    'rf__min_samples_split': [2, 5, 10],\n",
    "    'rf__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV to find the best hyperparameters\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions, n_iter=20, cv=5, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = random_search.predict(X_test)\n",
    "\n",
    "# Display classification report\n",
    "print(\"Best Parameters Found:\\n\", random_search.best_params_)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Combine the test set results (Job Description, Original Label, and Predicted Label)\n",
    "results_df = pd.DataFrame({\n",
    "    'Job Description': X_test,\n",
    "    'Original Label': y_test,\n",
    "    'Predicted Label': y_pred\n",
    "})\n",
    "\n",
    "# Display the output (Job Description, Original Label, Predicted Label)\n",
    "print(\"\\nTest Set Results:\\n\")\n",
    "print(results_df)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv('test_set_predictions_with_hyperparameters.csv', index=False)\n",
    "\n",
    "# Example usage to predict a label for a new job description:\n",
    "def predict_job_label(description):\n",
    "    description = preprocess_text(description)  # Preprocess the input\n",
    "    prediction = random_search.predict([description])  # Make prediction\n",
    "    return prediction[0]  # Return the predicted label\n",
    "\n",
    "# Predict a new job description (optional)\n",
    "new_description = input(\"\\nEnter a job description: \")\n",
    "predicted_label = predict_job_label(new_description)\n",
    "print(f\"\\nPredicted label for the given job description: {predicted_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters Found:\n",
      " {'rf__n_estimators': 100, 'rf__min_samples_split': 2, 'rf__min_samples_leaf': 1, 'rf__max_depth': 30}\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "  Response A       0.88      0.85      0.87        34\n",
      "  Response B       0.65      0.81      0.72        21\n",
      "  Response C       0.75      0.38      0.50         8\n",
      "\n",
      "    accuracy                           0.78        63\n",
      "   macro avg       0.76      0.68      0.70        63\n",
      "weighted avg       0.79      0.78      0.77        63\n",
      "\n",
      "\n",
      "Test Set Results:\n",
      "\n",
      "                                       Job Description Original Label  \\\n",
      "30           develop interactive data report dashboard     Response B   \n",
      "172   provide guidance campaign strategy communication     Response A   \n",
      "84             manage contract campus facility service     Response B   \n",
      "199  occasionally assist training staff av equipmen...     Response C   \n",
      "60                    provide financial advice student     Response B   \n",
      "..                                                 ...            ...   \n",
      "65                ensure tool material well maintained     Response B   \n",
      "5    provide occasional training communication stra...     Response B   \n",
      "146              lead meeting ensure key objective met     Response A   \n",
      "56           oversee troubleshooting technical support     Response A   \n",
      "97     train staff maintenance protocol safety measure     Response A   \n",
      "\n",
      "    Predicted Label  \n",
      "30       Response B  \n",
      "172      Response B  \n",
      "84       Response B  \n",
      "199      Response C  \n",
      "60       Response B  \n",
      "..              ...  \n",
      "65       Response B  \n",
      "5        Response A  \n",
      "146      Response A  \n",
      "56       Response C  \n",
      "97       Response A  \n",
      "\n",
      "[63 rows x 3 columns]\n",
      "\n",
      "Example Job Description: \"Occasionally guide team members on digital marketing strategies\"\n",
      "Original Label: Response B\n",
      "Predicted Label: Response B\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "# Uncomment these lines if you haven't downloaded NLTK resources yet\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('team.csv', encoding='ISO-8859-1')\n",
    "\n",
    "# Clean column names by stripping whitespaces\n",
    "data.columns = data.columns.str.strip()\n",
    "\n",
    "# Preprocessing function to clean and lemmatize text\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Lemmatize and remove stopwords\n",
    "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n",
    "    return text\n",
    "\n",
    "# Apply the preprocessing to job descriptions\n",
    "data['Job Description'] = data['Job Description'].apply(preprocess_text)\n",
    "\n",
    "# Prepare the data\n",
    "X = data['Job Description']  # Features (Job Descriptions)\n",
    "y = data['label']  # Target (Labels)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a pipeline that includes both TF-IDF Vectorizer and RandomForestClassifier\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('rf', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Hyperparameter tuning using RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    'rf__n_estimators': [50, 100, 200, 300],\n",
    "    'rf__max_depth': [10, 20, 30, None],\n",
    "    'rf__min_samples_split': [2, 5, 10],\n",
    "    'rf__min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# Perform RandomizedSearchCV to find the best hyperparameters\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions, n_iter=20, cv=5, random_state=42, n_jobs=-1)\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = random_search.predict(X_test)\n",
    "\n",
    "# Display classification report\n",
    "print(\"Best Parameters Found:\\n\", random_search.best_params_)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Combine the test set results (Job Description, Original Label, and Predicted Label)\n",
    "results_df = pd.DataFrame({\n",
    "    'Job Description': X_test,\n",
    "    'Original Label': y_test,\n",
    "    'Predicted Label': y_pred\n",
    "})\n",
    "\n",
    "# Display the output (Job Description, Original Label, Predicted Label)\n",
    "print(\"\\nTest Set Results:\\n\")\n",
    "print(results_df)\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results_df.to_csv('test_set_predictions_with_hyperparameters.csv', index=False)\n",
    "\n",
    "# Function to predict the label for a new job description\n",
    "def predict_job_label(description, data, random_search):\n",
    "    # Preprocess the input description\n",
    "    processed_description = preprocess_text(description)\n",
    "    \n",
    "    # Predict the label using the model\n",
    "    predicted_label = random_search.predict([processed_description])[0]\n",
    "    \n",
    "    # Try to find the original label from the dataset (if it exists)\n",
    "    original_label = data[data['Job Description'] == processed_description]['label']\n",
    "    \n",
    "    if not original_label.empty:\n",
    "        original_label = original_label.values[0]\n",
    "    else:\n",
    "        original_label = \"Not available in the dataset\"\n",
    "    \n",
    "    return original_label, predicted_label\n",
    "\n",
    "# Example usage:\n",
    "new_description = input(\"\\nEnter a job description: \")\n",
    "original_label, predicted_label = predict_job_label(new_description, data, random_search)\n",
    "print(f\"\\nExample Job Description: \\\"{new_description}\\\"\")\n",
    "print(f\"Original Label: {original_label}\")\n",
    "print(f\"Predicted Label: {predicted_label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Example Job Description: \"Occasionally guide team members on digital marketing strategies\"\n",
      "Original Label: Response B\n",
      "Predicted Label: Response B\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "# Uncomment if NLTK resources need to be downloaded\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv('team.csv', encoding='ISO-8859-1')\n",
    "data.columns = data.columns.str.strip()  # Clean column names\n",
    "\n",
    "# Preprocessing function to clean text\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    return ' '.join([lemmatizer.lemmatize(word) for word in text.split() if word not in stop_words])\n",
    "\n",
    "# Preprocess job descriptions\n",
    "data['Job Description'] = data['Job Description'].apply(preprocess_text)\n",
    "\n",
    "# Train-Test Split\n",
    "X = data['Job Description']\n",
    "y = data['label']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Create a TF-IDF + Logistic Regression pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('lr', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Function to predict and compare original and predicted labels\n",
    "def predict_job_label(description, data, model):\n",
    "    processed_description = preprocess_text(description)\n",
    "    predicted_label = model.predict([processed_description])[0]\n",
    "    original_label = data[data['Job Description'] == processed_description]['label']\n",
    "    original_label = original_label.values[0] if not original_label.empty else \"Not available in dataset\"\n",
    "    return original_label, predicted_label\n",
    "\n",
    "# Example usage\n",
    "new_description = input(\"Enter a job description: \")\n",
    "original_label, predicted_label = predict_job_label(new_description, data, pipeline)\n",
    "print(f\"\\nExample Job Description: \\\"{new_description}\\\"\")\n",
    "print(f\"Original Label: {original_label}\")\n",
    "print(f\"Predicted Label: {predicted_label}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "“virtual”env”",
   "language": "python",
   "name": "myvirtualenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
